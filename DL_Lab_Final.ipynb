{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 86518,
          "databundleVersionId": 9809560,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 30805,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bda0ef7d684441ed9f49afff5bc73c25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_11981417fd3044afb909838e38d3deb9",
              "IPY_MODEL_3ebc1880888b4df6883b52232fa5d88f",
              "IPY_MODEL_3abbef734b5447499f1f8c0e893c2734"
            ],
            "layout": "IPY_MODEL_94c3257ec3834b52921faf017ba5f52b"
          }
        },
        "11981417fd3044afb909838e38d3deb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a9b6d8294b248f591456ff6e4644dd5",
            "placeholder": "​",
            "style": "IPY_MODEL_936a135aea9240dbb9527951174e8e87",
            "value": "100%"
          }
        },
        "3ebc1880888b4df6883b52232fa5d88f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8b23e7edb0f44cf84c6bee2b577532b",
            "max": 57477,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6adab1a3114f4dbf90a766df77aa479b",
            "value": 57477
          }
        },
        "3abbef734b5447499f1f8c0e893c2734": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97ef682419e44f0eab744044dc797eb0",
            "placeholder": "​",
            "style": "IPY_MODEL_f904eb7dc98f4abf95c2cffdfb723255",
            "value": " 57477/57477 [00:16&lt;00:00, 3662.16it/s]"
          }
        },
        "94c3257ec3834b52921faf017ba5f52b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a9b6d8294b248f591456ff6e4644dd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "936a135aea9240dbb9527951174e8e87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a8b23e7edb0f44cf84c6bee2b577532b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6adab1a3114f4dbf90a766df77aa479b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "97ef682419e44f0eab744044dc797eb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f904eb7dc98f4abf95c2cffdfb723255": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "85287f32eae746709a21593f9c8cbeb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5a7db1c1997c4df1a551b96aa8c330be",
              "IPY_MODEL_3e3d156a5bba469399b8735efa3f21f5",
              "IPY_MODEL_f1956da38454405fa07438b3929673a8"
            ],
            "layout": "IPY_MODEL_577eeeee847c483fa8a3e7e91de58d5e"
          }
        },
        "5a7db1c1997c4df1a551b96aa8c330be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_064951b4aec0427ea19566197500db20",
            "placeholder": "​",
            "style": "IPY_MODEL_640e813043c44be0bd6db7b7821e78ff",
            "value": "100%"
          }
        },
        "3e3d156a5bba469399b8735efa3f21f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7adf8de1cae473c8045758031538e2b",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_536dcd96ccdb42f18fbdedd929c3ecb6",
            "value": 3
          }
        },
        "f1956da38454405fa07438b3929673a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04390f57514b424a9854c1498582469a",
            "placeholder": "​",
            "style": "IPY_MODEL_0a5c4ce2762044e4b3b4fb8b7de52803",
            "value": " 3/3 [00:00&lt;00:00, 281.48it/s]"
          }
        },
        "577eeeee847c483fa8a3e7e91de58d5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "064951b4aec0427ea19566197500db20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "640e813043c44be0bd6db7b7821e78ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e7adf8de1cae473c8045758031538e2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "536dcd96ccdb42f18fbdedd929c3ecb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "04390f57514b424a9854c1498582469a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a5c4ce2762044e4b3b4fb8b7de52803": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/One-78/Deep_Learning_Lab_Project/blob/main/DL_Lab_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "llm_classification_finetuning_path = kagglehub.competition_download('llm-classification-finetuning')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "5WUiWKwkuGgn",
        "outputId": "277b4f74-5cca-454d-b111-1e35af54910a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/competitions/data/download-all/llm-classification-finetuning...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 57.0M/57.0M [00:00<00:00, 80.9MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import os\n",
        "from tqdm.notebook import tqdm\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import TextVectorization, Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout, Input\n",
        "from tensorflow.keras.models import Sequential\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-08T12:14:11.265731Z",
          "iopub.execute_input": "2024-12-08T12:14:11.266152Z",
          "iopub.status.idle": "2024-12-08T12:14:23.825487Z",
          "shell.execute_reply.started": "2024-12-08T12:14:11.266122Z",
          "shell.execute_reply": "2024-12-08T12:14:23.824787Z"
        },
        "id": "avDmosKMuGgo"
      },
      "outputs": [],
      "execution_count": 5
    },
    {
      "cell_type": "code",
      "source": [
        "class CFG:\n",
        "    seeds = [42, 119, 2020]\n",
        "    vocab_size = 20000\n",
        "    max_length = 256\n",
        "    batch_size = 128\n",
        "    fine_tune_epochs = 40\n",
        "    learning_rate = 1e-3  # High LR\n",
        "    warmup_epochs = 2  # Add warmup\n",
        "    weight_decay = 0.01  # Add regularization"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-08T12:14:23.826889Z",
          "iopub.execute_input": "2024-12-08T12:14:23.827372Z",
          "iopub.status.idle": "2024-12-08T12:14:23.832144Z",
          "shell.execute_reply.started": "2024-12-08T12:14:23.827326Z",
          "shell.execute_reply": "2024-12-08T12:14:23.830999Z"
        },
        "id": "ku4z70VKuGgo"
      },
      "outputs": [],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(os.path.join(llm_classification_finetuning_path, 'train.csv'))\n",
        "train_df.head()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-08T12:14:23.833666Z",
          "iopub.execute_input": "2024-12-08T12:14:23.83405Z",
          "iopub.status.idle": "2024-12-08T12:14:27.171447Z",
          "shell.execute_reply.started": "2024-12-08T12:14:23.834009Z",
          "shell.execute_reply": "2024-12-08T12:14:27.170516Z"
        },
        "id": "tFkq5NQvuGgp",
        "outputId": "fa462ce9-8620-4f98-fd08-b4d0052f491f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       id             model_a              model_b  \\\n",
              "0   30192  gpt-4-1106-preview           gpt-4-0613   \n",
              "1   53567           koala-13b           gpt-4-0613   \n",
              "2   65089  gpt-3.5-turbo-0613       mistral-medium   \n",
              "3   96401    llama-2-13b-chat  mistral-7b-instruct   \n",
              "4  198779           koala-13b   gpt-3.5-turbo-0314   \n",
              "\n",
              "                                              prompt  \\\n",
              "0  [\"Is it morally right to try to have a certain...   \n",
              "1  [\"What is the difference between marriage lice...   \n",
              "2  [\"explain function calling. how would you call...   \n",
              "3  [\"How can I create a test set for a very rare ...   \n",
              "4  [\"What is the best way to travel from Tel-Aviv...   \n",
              "\n",
              "                                          response_a  \\\n",
              "0  [\"The question of whether it is morally right ...   \n",
              "1  [\"A marriage license is a legal document that ...   \n",
              "2  [\"Function calling is the process of invoking ...   \n",
              "3  [\"Creating a test set for a very rare category...   \n",
              "4  [\"The best way to travel from Tel Aviv to Jeru...   \n",
              "\n",
              "                                          response_b  winner_model_a  \\\n",
              "0  [\"As an AI, I don't have personal beliefs or o...               1   \n",
              "1  [\"A marriage license and a marriage certificat...               0   \n",
              "2  [\"Function calling is the process of invoking ...               0   \n",
              "3  [\"When building a classifier for a very rare c...               1   \n",
              "4  [\"The best way to travel from Tel-Aviv to Jeru...               0   \n",
              "\n",
              "   winner_model_b  winner_tie  \n",
              "0               0           0  \n",
              "1               1           0  \n",
              "2               0           1  \n",
              "3               0           0  \n",
              "4               1           0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-af06a878-9ea3-49ba-aa3f-90c71a752a6d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>model_a</th>\n",
              "      <th>model_b</th>\n",
              "      <th>prompt</th>\n",
              "      <th>response_a</th>\n",
              "      <th>response_b</th>\n",
              "      <th>winner_model_a</th>\n",
              "      <th>winner_model_b</th>\n",
              "      <th>winner_tie</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>30192</td>\n",
              "      <td>gpt-4-1106-preview</td>\n",
              "      <td>gpt-4-0613</td>\n",
              "      <td>[\"Is it morally right to try to have a certain...</td>\n",
              "      <td>[\"The question of whether it is morally right ...</td>\n",
              "      <td>[\"As an AI, I don't have personal beliefs or o...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>53567</td>\n",
              "      <td>koala-13b</td>\n",
              "      <td>gpt-4-0613</td>\n",
              "      <td>[\"What is the difference between marriage lice...</td>\n",
              "      <td>[\"A marriage license is a legal document that ...</td>\n",
              "      <td>[\"A marriage license and a marriage certificat...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>65089</td>\n",
              "      <td>gpt-3.5-turbo-0613</td>\n",
              "      <td>mistral-medium</td>\n",
              "      <td>[\"explain function calling. how would you call...</td>\n",
              "      <td>[\"Function calling is the process of invoking ...</td>\n",
              "      <td>[\"Function calling is the process of invoking ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>96401</td>\n",
              "      <td>llama-2-13b-chat</td>\n",
              "      <td>mistral-7b-instruct</td>\n",
              "      <td>[\"How can I create a test set for a very rare ...</td>\n",
              "      <td>[\"Creating a test set for a very rare category...</td>\n",
              "      <td>[\"When building a classifier for a very rare c...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>198779</td>\n",
              "      <td>koala-13b</td>\n",
              "      <td>gpt-3.5-turbo-0314</td>\n",
              "      <td>[\"What is the best way to travel from Tel-Aviv...</td>\n",
              "      <td>[\"The best way to travel from Tel Aviv to Jeru...</td>\n",
              "      <td>[\"The best way to travel from Tel-Aviv to Jeru...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-af06a878-9ea3-49ba-aa3f-90c71a752a6d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-af06a878-9ea3-49ba-aa3f-90c71a752a6d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-af06a878-9ea3-49ba-aa3f-90c71a752a6d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-35f2347b-de3d-4fc1-a1e0-e9e00f512d09\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-35f2347b-de3d-4fc1-a1e0-e9e00f512d09')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-35f2347b-de3d-4fc1-a1e0-e9e00f512d09 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df",
              "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 57477,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1238326827,\n        \"min\": 30192,\n        \"max\": 4294947231,\n        \"num_unique_values\": 57477,\n        \"samples\": [\n          2785062085,\n          48259531,\n          3622731894\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"model_a\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 64,\n        \"samples\": [\n          \"mistral-7b-instruct\",\n          \"guanaco-33b\",\n          \"gpt-4-1106-preview\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"model_b\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 64,\n        \"samples\": [\n          \"llama2-70b-steerlm-chat\",\n          \"llama-13b\",\n          \"gpt-4-0613\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prompt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 51734,\n        \"samples\": [\n          \"[\\\"Are autoregressive language models (e.g. GPT-3) currently more popular than auto-encoding language models (e.g. BERT)? If so, what are the explanations?\\\"]\",\n          \"[\\\"Write a c++ algorithm that aims to find the rightmost zero in a binary representation, flip it to a one, and flip any 1s to its right\\\"]\",\n          \"[\\\"What is J\\\\u00e9r\\\\u00f4me WAX ?\\\"]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"response_a\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 56566,\n        \"samples\": [\n          \"[\\\"Tea is grown commercially in the Azores, an autonomous region of Portugal. The main tea-producing estates are located on the island of S\\\\u00e3o Miguel, where the only commercial tea plantations in Europe can be found. The most well-known tea estates on S\\\\u00e3o Miguel are Gorreana Tea Estate and Porto Formoso Tea Factory.\\\"]\",\n          \"[\\\"Sure! Here's an example to illustrate how function pointers work in C:\\\\n\\\\n```c\\\\n#include <stdio.h>\\\\n\\\\n\\\\/\\\\/ Function to be pointed to\\\\nint add(int a, int b) {\\\\n    return a + b;\\\\n}\\\\n\\\\n\\\\/\\\\/ Function to demonstrate function pointers\\\\nvoid functionPointerExample(int (*funcPtr)(int, int)) {\\\\n    int result = funcPtr(5, 10);\\\\n    printf(\\\\\\\"Result: %d\\\\\\\\n\\\\\\\", result);\\\\n}\\\\n\\\\nint main() {\\\\n    \\\\/\\\\/ Use the address-of operator (&) to get the address of the add function\\\\n    int (*addPtr)(int, int) = &add;\\\\n\\\\n    \\\\/\\\\/ Call the functionPointerExample function and pass the address of the add function\\\\n    functionPointerExample(addPtr);\\\\n\\\\n    \\\\/\\\\/ Call the add function directly\\\\n    int result = add(15, 20);\\\\n    printf(\\\\\\\"Result: %d\\\\\\\\n\\\\\\\", result);\\\\n\\\\n    return 0;\\\\n}\\\\n```\\\\n\\\\nIn this example, we define a function `add` that takes two integers as arguments and returns their sum.\\\\n\\\\nWe then define a function `functionPointerExample` that takes a function pointer as an argument. This function calls the pointed-to function passing it two integers, and then prints the result.\\\\n\\\\nIn the main function, we create a function pointer `addPtr` which points to the `add` function. We then call the `functionPointerExample` function passing the address of the `add` function using the `&` operator.\\\\n\\\\nFinally, we call the `add` function directly and store the result in a variable `result`.\\\\n\\\\nI hope this helps you understand how function pointers work in C! Let me know if you have any other questions.\\\",\\\"To define a function pointer within a struct, you can define a member variable of the struct as a pointer to a function with a specific return type and argument list. Here's an example:\\\\n\\\\n```c\\\\n#include <stdio.h>\\\\n\\\\n\\\\/\\\\/ Define a structure with a function pointer member\\\\ntypedef struct {\\\\n    int (*calculate)(int);\\\\n} Calculator;\\\\n\\\\n\\\\/\\\\/ Function to be pointed to\\\\nint add(int num) {\\\\n    return num + 10;\\\\n}\\\\n\\\\n\\\\/\\\\/ Function to demonstrate using a function pointer within a struct\\\\nvoid useCalculator(Calculator calculator) {\\\\n    int result = calculator.calculate(15);\\\\n    printf(\\\\\\\"Result: %d\\\\\\\\n\\\\\\\", result);\\\\n}\\\\n\\\\nint main() {\\\\n    \\\\/\\\\/ Create a Calculator struct and initialize the function pointer member\\\\n    Calculator calculator = { add };\\\\n\\\\n    \\\\/\\\\/ Call the useCalculator function and pass the calculator struct\\\\n    useCalculator(calculator);\\\\n\\\\n    return 0;\\\\n}\\\\n```\\\\n\\\\nIn this example, we define a `typedef` for our `Calculator` struct, which has a single member `calculate` that is a pointer to a function that takes an integer as an argument and returns an integer.\\\\n\\\\nWe then define a function `add` that adds 10 to the input integer and return the result.\\\\n\\\\nWe define a function `useCalculator` that takes a `Calculator` struct as an argument and invokes the `calculate` member function of the struct with an argument of 15.\\\\n\\\\nIn the `main` function, we create a `Calculator` struct and initialize its `calculate` member with the address of the `add` function. We then call the `useCalculator` function passing the `calculator` struct.\\\\n\\\\nI hope this helps you understand how to define a function pointer within a struct in C! Let me know if you have any other questions.\\\"]\",\n          \"[\\\"In the depths of a dark and mysterious cave, there lived a heavily pregnant cavewoman named Ula. Her thick, matted hair cascaded down her back, and her skin was tanned and rough from years of living in the harsh wilderness. Ula's husband, Kadan, was a skilled hunter and provided for their small tribe. But lately, even his sharpest arrows seemed to fall short, and food had become scarce.\\\\n\\\\nUla felt a deep ache in her bones and her swollen belly. It was the third trimester, and her baby was growing rapidly. She wondered if she would ever be able to give birth in the cramped, narrow cave. Ula's tribe had no midwife, and her only hope was to rely on the wisdom passed down from her own mother.\\\\n\\\\nOne day, while Kadan was out hunting, Ula went into labor. Her screams echoed through the cave, and her tribe gathered around her in a frenzy. Ula's eyes widened as she felt the intense pain of contractions. She was afraid for her baby's life and her own.\\\\n\\\\nThe tribe tried to comfort Ula, but their efforts fell short. Ula's baby was too big, and the birth seemed impossible. Hours passed, and Ula lost all strength. Her tribe watched in horror as Ula's life slipped away. Suddenly, a loud cry broke the silence. Ula's baby had been born, and he was healthy and strong.\\\\n\\\\nThe tribe rejoiced at the sight of the newborn. They named him Kade, after Ula's husband, Kadan. Kade was a symbol of hope and resilience, and his birth brought new life and energy to the tribe.\\\\n\\\\nAs Ula took her last breath, she whispered to Kade, \\\\\\\"May you grow up to be a fierce and proud caveman, just like your father.\\\\\\\" Ula's legacy lived on through her son, and her tribe honored her memory by carving her name into the walls of the cave. The story of Ula, the heavily pregnant cavewoman who defied death to give birth to Kade, became a legend that would be passed down through the generations.\\\"]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"response_b\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 56609,\n        \"samples\": [\n          \"[\\\"Unfortunately, I do not have enough context to provide specific details about \\\\\\\"mobility123\\\\\\\" in New Jersey. Mobility123 is not a term I am familiar with. To provide more useful information, it would be helpful if you could clarify what kind of service, company, or product mobility123 refers to, as well as any additional details about what you would like to know in relation to New Jersey. Please provide some more context and details so that I can try to assist. Let me know if you can share more information!\\\"]\",\n          \"[\\\"Abby, Amber, Amra, Arin, Arna, Ashy, Bari, Bett, Brix, Bryn, Brin, Brynne, Ciri, Cyrn, Ebby, Ebri, Elbr, Elmry, Embr, Raby, Reba\\\"]\",\n          \"[\\\"It's great that your child is considering how to communicate with her friends in a way that doesn't upset them. Here are some tips that may help:\\\\n\\\\n1. Listen actively: Encourage your child to listen to her friends without interrupting or judging them. This means paying attention to what they're saying, asking questions to clarify their thoughts, and acknowledging their feelings.\\\\n2. Use kind words: Remind your child to use kind and respectful language when talking to her friends. This means avoiding hurtful words or tone, and being mindful of how her words may be perceived by others.\\\\n3. Be empathetic: Encourage your child to try to see things from her friends' perspective and to understand their feelings and needs. This means putting herself in their shoes and considering how they might be feeling.\\\\n4. Avoid gossip: Remind your child that gossiping about her friends can be hurtful and damaging to their relationships. Encourage her to avoid talking about her friends behind their backs and to speak to them directly if she has concerns.\\\\n5. Be honest: Remind your child that honesty is always the best policy, even if it's difficult to hear. Encourage her to be open and truthful with her friends, but also to be gentle and considerate in how she delivers her message.\\\\n\\\\nBy following these tips, your child can learn how to communicate effectively with her friends without upsetting them.\\\"]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"winner_model_a\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"winner_model_b\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"winner_tie\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "execution_count": 5
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_list = []\n",
        "targets = []\n",
        "for i in tqdm(range(len(train_df))):\n",
        "    prompts = json.loads(train_df.iloc[i][\"prompt\"])\n",
        "    response_a = json.loads(train_df.iloc[i][\"response_a\"])\n",
        "    response_b = json.loads(train_df.iloc[i][\"response_b\"])\n",
        "    conversation_a = \"\"\n",
        "    conversation_b = \"\"\n",
        "    for j in range(len(prompts)):\n",
        "        if response_a[j] is None:\n",
        "            response_a[j] = \"None\"\n",
        "        if response_b[j] is None:\n",
        "            response_b[j] = \"None\"\n",
        "        conversation_a += prompts[j] + \"\\n\"\n",
        "        conversation_a += response_a[j] + \"\\n\"\n",
        "        conversation_b += prompts[j] + \"\\n\"\n",
        "        conversation_b += response_b[j] + \"\\n\"\n",
        "    prompt_list.append((conversation_a, conversation_b))\n",
        "    if train_df.iloc[i][\"winner_tie\"] == 1:\n",
        "        targets.append(0)\n",
        "    if train_df.iloc[i][\"winner_model_a\"] == 1:\n",
        "        targets.append(1)\n",
        "    if train_df.iloc[i][\"winner_model_b\"] == 1:\n",
        "        targets.append(2)\n",
        "len(prompt_list)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-08T12:14:27.173724Z",
          "iopub.execute_input": "2024-12-08T12:14:27.174012Z",
          "iopub.status.idle": "2024-12-08T12:14:43.745351Z",
          "shell.execute_reply.started": "2024-12-08T12:14:27.173986Z",
          "shell.execute_reply": "2024-12-08T12:14:43.74454Z"
        },
        "id": "YP7eWpStuGgp",
        "outputId": "3f0a2126-3e9a-4d0a-9b73-7f25ade3599d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "bda0ef7d684441ed9f49afff5bc73c25",
            "11981417fd3044afb909838e38d3deb9",
            "3ebc1880888b4df6883b52232fa5d88f",
            "3abbef734b5447499f1f8c0e893c2734",
            "94c3257ec3834b52921faf017ba5f52b",
            "6a9b6d8294b248f591456ff6e4644dd5",
            "936a135aea9240dbb9527951174e8e87",
            "a8b23e7edb0f44cf84c6bee2b577532b",
            "6adab1a3114f4dbf90a766df77aa479b",
            "97ef682419e44f0eab744044dc797eb0",
            "f904eb7dc98f4abf95c2cffdfb723255"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/57477 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bda0ef7d684441ed9f49afff5bc73c25"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "57477"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "execution_count": 17
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Define TextVectorization layer\n",
        "text_vectorizer = TextVectorization(max_tokens=CFG.vocab_size, output_mode='int', output_sequence_length=CFG.max_length)\n",
        "text_vectorizer.adapt([item[0] for item in prompt_list] + [item[1] for item in prompt_list])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-08T12:14:43.746546Z",
          "iopub.execute_input": "2024-12-08T12:14:43.746816Z",
          "iopub.status.idle": "2024-12-08T12:14:56.640344Z",
          "shell.execute_reply.started": "2024-12-08T12:14:43.746791Z",
          "shell.execute_reply": "2024-12-08T12:14:56.639595Z"
        },
        "id": "riJlZNhouGgq"
      },
      "outputs": [],
      "execution_count": 18
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataset(prompt_list, targets, shuffle=True, batch_size=128):\n",
        "    part1 = [item[0] for item in prompt_list]\n",
        "    part2 = [item[1] for item in prompt_list]\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(((part1, part2), targets))\n",
        "    if shuffle:\n",
        "        dataset = dataset.shuffle(buffer_size=2048)\n",
        "    dataset = dataset.batch(CFG.batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "    return dataset"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-08T12:14:56.648951Z",
          "iopub.execute_input": "2024-12-08T12:14:56.649233Z",
          "iopub.status.idle": "2024-12-08T12:14:56.66058Z",
          "shell.execute_reply.started": "2024-12-08T12:14:56.649208Z",
          "shell.execute_reply": "2024-12-08T12:14:56.659717Z"
        },
        "id": "MxBz1MiKuGgr"
      },
      "outputs": [],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "source": [
        "def get_base_model(inputs, embedding):\n",
        "    x = text_vectorizer(inputs)\n",
        "    x = embedding(x)\n",
        "    x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True))(x)\n",
        "    return x\n",
        "def get_model():\n",
        "    inputs1 = tf.keras.Input(shape=(1,), dtype=tf.string)\n",
        "    inputs2 = tf.keras.Input(shape=(1,), dtype=tf.string)\n",
        "    embedding = tf.keras.layers.Embedding(input_dim=CFG.vocab_size, output_dim=64, mask_zero=True)\n",
        "    x1 = get_base_model(inputs1, embedding)\n",
        "    x2 = get_base_model(inputs2, embedding)\n",
        "    x = tf.keras.layers.Concatenate()([x1, x2])\n",
        "    x = tf.keras.layers.Conv1D(32, 3, activation=\"relu\")(x)\n",
        "    x = tf.keras.layers.Conv1D(32, 3, activation=\"relu\")(x)\n",
        "    x = tf.keras.layers.SpatialDropout1D(0.2)(x)\n",
        "    x = tf.keras.layers.MaxPooling1D()(x)\n",
        "    x = tf.keras.layers.Conv1D(64, 3, activation=\"relu\")(x)\n",
        "    x = tf.keras.layers.Conv1D(64, 3, activation=\"relu\")(x)\n",
        "    x = tf.keras.layers.SpatialDropout1D(0.2)(x)\n",
        "    x = tf.keras.layers.MaxPooling1D()(x)\n",
        "    x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
        "    x = tf.keras.layers.Dropout(0.3)(x)\n",
        "    x = tf.keras.layers.Dense(128, activation=\"swish\")(x)\n",
        "    outputs = tf.keras.layers.Dense(3, activation=\"softmax\")(x)\n",
        "    model = tf.keras.Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
        "\n",
        "    ## model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-08T12:14:56.661544Z",
          "iopub.execute_input": "2024-12-08T12:14:56.661849Z",
          "iopub.status.idle": "2024-12-08T12:14:56.693601Z",
          "shell.execute_reply.started": "2024-12-08T12:14:56.661814Z",
          "shell.execute_reply": "2024-12-08T12:14:56.693025Z"
        },
        "id": "rLgoOjtnuGgs"
      },
      "outputs": [],
      "execution_count": 9
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the model with\n",
        "    vocab_size = 20000\n",
        "    max_length = 1024\n",
        "    batch_size = 64  \n",
        "    fine_tune_epochs = 15  \n",
        "    learning_rate = 2e-5  \n",
        "    warmup_epochs = 2\n",
        "    weight_decay = 0.01  "
      ],
      "metadata": {
        "id": "LV7VQnf8Mngz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine tuning and training the model\n",
        "models = []\n",
        "for seed in CFG.seeds:\n",
        "    model_name = f\"model_{seed}.keras\"\n",
        "    model_name_path = os.path.join(llm_classification_finetuning_path, model_name)\n",
        "\n",
        "    train_texts, valid_texts, train_labels, valid_labels = train_test_split(\n",
        "        prompt_list, targets, test_size=0.2, random_state=seed, stratify=targets  # Add stratify\n",
        "    )\n",
        "    valid_ds = get_dataset(valid_texts, valid_labels, shuffle=False)\n",
        "\n",
        "    if not os.path.exists(model_name_path):\n",
        "        train_ds = get_dataset(train_texts, train_labels)\n",
        "        model = get_model()\n",
        "\n",
        "        # Use AdamW with weight decay\n",
        "        optimizer = tf.keras.optimizers.AdamW(\n",
        "            learning_rate=CFG.learning_rate,\n",
        "            weight_decay=CFG.weight_decay\n",
        "        )\n",
        "\n",
        "        model.compile(\n",
        "            optimizer=optimizer,\n",
        "            loss='sparse_categorical_crossentropy',  # or your loss\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "\n",
        "        # Callbacks\n",
        "        checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "            filepath=model_name_path,\n",
        "            monitor='val_loss',\n",
        "            mode='min',\n",
        "            save_best_only=True,\n",
        "            save_weights_only=False,\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
        "            monitor='val_loss',\n",
        "            patience=5,  # Increased patience\n",
        "            verbose=1,\n",
        "            restore_best_weights=True,\n",
        "            min_delta=1e-4  # Add minimum improvement threshold\n",
        "        )\n",
        "\n",
        "        reduce_lr_callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "            monitor='val_loss',\n",
        "            factor=0.3,  # More aggressive reduction\n",
        "            patience=3,  # Increased patience\n",
        "            min_lr=1e-7,\n",
        "            verbose=1,\n",
        "            min_delta=1e-4\n",
        "        )\n",
        "\n",
        "        # Optional: Add learning rate warmup\n",
        "        def lr_schedule(epoch):\n",
        "            if epoch < CFG.warmup_epochs:\n",
        "                return CFG.learning_rate * (epoch + 1) / CFG.warmup_epochs\n",
        "            return CFG.learning_rate\n",
        "\n",
        "        lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lr_schedule, verbose=1)\n",
        "\n",
        "        # Fine-tune\n",
        "        history = model.fit(\n",
        "            train_ds,\n",
        "            epochs=CFG.fine_tune_epochs,\n",
        "            validation_data=valid_ds,\n",
        "            callbacks=[checkpoint_callback, early_stopping_callback, reduce_lr_callback, lr_scheduler],\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        # Load best weights\n",
        "        model = tf.keras.models.load_model(model_name_path)\n",
        "    else:\n",
        "        model = tf.keras.models.load_model(model_name_path)\n",
        "\n",
        "    loss, acc = model.evaluate(valid_ds, verbose=0)\n",
        "    print(f\"Seed {seed} - Validation Loss: {loss:.4f} | Validation Accuracy: {acc * 100:.2f}%\")\n",
        "    if 'history' in locals():\n",
        "        print(f\"Best epoch: {np.argmin(history.history['val_loss']) + 1}\")\n",
        "    models.append(model)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-08T12:14:56.694442Z",
          "iopub.execute_input": "2024-12-08T12:14:56.694662Z",
          "iopub.status.idle": "2024-12-08T12:24:08.684997Z",
          "shell.execute_reply.started": "2024-12-08T12:14:56.69464Z",
          "shell.execute_reply": "2024-12-08T12:24:08.684052Z"
        },
        "id": "pmK_OcjguGgt",
        "outputId": "0291889d-370a-488c-ffff-a4ce6e3fc946",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/layer.py:965: UserWarning: Layer 'conv1d' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed 42 - Validation Loss: 0.9853 | Validation Accuracy: 53.52%\n",
            "Best epoch: 2\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 1/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/layer.py:965: UserWarning: Layer 'conv1d_8' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.3515 - loss: 1.0985\n",
            "Epoch 1: val_loss improved from inf to 1.09758, saving model to /root/.cache/kagglehub/competitions/llm-classification-finetuning/model_119.keras\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 146ms/step - accuracy: 0.3515 - loss: 1.0985 - val_accuracy: 0.3930 - val_loss: 1.0976 - learning_rate: 1.0000e-05\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 2e-05.\n",
            "Epoch 2/15\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.3815 - loss: 1.0946\n",
            "Epoch 2: val_loss improved from 1.09758 to 1.07515, saving model to /root/.cache/kagglehub/competitions/llm-classification-finetuning/model_119.keras\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 146ms/step - accuracy: 0.3816 - loss: 1.0946 - val_accuracy: 0.4229 - val_loss: 1.0751 - learning_rate: 2.0000e-05\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 2e-05.\n",
            "Epoch 3/15\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.4152 - loss: 1.0761\n",
            "Epoch 3: val_loss improved from 1.07515 to 1.06751, saving model to /root/.cache/kagglehub/competitions/llm-classification-finetuning/model_119.keras\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 145ms/step - accuracy: 0.4152 - loss: 1.0761 - val_accuracy: 0.4251 - val_loss: 1.0675 - learning_rate: 2.0000e-05\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 2e-05.\n",
            "Epoch 4/15\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.4227 - loss: 1.0695\n",
            "Epoch 4: val_loss improved from 1.06751 to 1.06556, saving model to /root/.cache/kagglehub/competitions/llm-classification-finetuning/model_119.keras\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 145ms/step - accuracy: 0.4227 - loss: 1.0695 - val_accuracy: 0.4296 - val_loss: 1.0656 - learning_rate: 2.0000e-05\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 2e-05.\n",
            "Epoch 5/15\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.4375 - loss: 1.0652\n",
            "Epoch 5: val_loss improved from 1.06556 to 1.06245, saving model to /root/.cache/kagglehub/competitions/llm-classification-finetuning/model_119.keras\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 147ms/step - accuracy: 0.4376 - loss: 1.0652 - val_accuracy: 0.4462 - val_loss: 1.0625 - learning_rate: 2.0000e-05\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 2e-05.\n",
            "Epoch 6/15\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.4507 - loss: 1.0593\n",
            "Epoch 6: val_loss improved from 1.06245 to 1.06187, saving model to /root/.cache/kagglehub/competitions/llm-classification-finetuning/model_119.keras\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 147ms/step - accuracy: 0.4507 - loss: 1.0593 - val_accuracy: 0.4479 - val_loss: 1.0619 - learning_rate: 2.0000e-05\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 2e-05.\n",
            "Epoch 7/15\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.4607 - loss: 1.0521\n",
            "Epoch 7: val_loss improved from 1.06187 to 1.06148, saving model to /root/.cache/kagglehub/competitions/llm-classification-finetuning/model_119.keras\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 146ms/step - accuracy: 0.4607 - loss: 1.0521 - val_accuracy: 0.4515 - val_loss: 1.0615 - learning_rate: 2.0000e-05\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 2e-05.\n",
            "Epoch 8/15\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.4743 - loss: 1.0423\n",
            "Epoch 8: val_loss did not improve from 1.06148\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 146ms/step - accuracy: 0.4743 - loss: 1.0422 - val_accuracy: 0.4551 - val_loss: 1.0658 - learning_rate: 2.0000e-05\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 2e-05.\n",
            "Epoch 9/15\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.4882 - loss: 1.0260\n",
            "Epoch 9: val_loss did not improve from 1.06148\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 147ms/step - accuracy: 0.4882 - loss: 1.0260 - val_accuracy: 0.4516 - val_loss: 1.0762 - learning_rate: 2.0000e-05\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 2e-05.\n",
            "Epoch 10/15\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.4996 - loss: 1.0072\n",
            "Epoch 10: val_loss did not improve from 1.06148\n",
            "\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 5.999999848427251e-06.\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 161ms/step - accuracy: 0.4996 - loss: 1.0072 - val_accuracy: 0.4499 - val_loss: 1.0920 - learning_rate: 6.0000e-06\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 2e-05.\n",
            "Epoch 11/15\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.5161 - loss: 0.9886\n",
            "Epoch 11: val_loss did not improve from 1.06148\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 148ms/step - accuracy: 0.5161 - loss: 0.9886 - val_accuracy: 0.4456 - val_loss: 1.1106 - learning_rate: 2.0000e-05\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 2e-05.\n",
            "Epoch 12/15\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.5294 - loss: 0.9699\n",
            "Epoch 12: val_loss did not improve from 1.06148\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 147ms/step - accuracy: 0.5294 - loss: 0.9699 - val_accuracy: 0.4425 - val_loss: 1.1249 - learning_rate: 2.0000e-05\n",
            "Epoch 12: early stopping\n",
            "Restoring model weights from the end of the best epoch: 7.\n",
            "Seed 119 - Validation Loss: 1.0615 | Validation Accuracy: 45.15%\n",
            "Best epoch: 7\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 1/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/layer.py:965: UserWarning: Layer 'conv1d_12' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.3549 - loss: 1.0983\n",
            "Epoch 1: val_loss improved from inf to 1.09733, saving model to /root/.cache/kagglehub/competitions/llm-classification-finetuning/model_2020.keras\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 147ms/step - accuracy: 0.3549 - loss: 1.0983 - val_accuracy: 0.3491 - val_loss: 1.0973 - learning_rate: 1.0000e-05\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 2e-05.\n",
            "Epoch 2/15\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.3730 - loss: 1.0945\n",
            "Epoch 2: val_loss improved from 1.09733 to 1.07653, saving model to /root/.cache/kagglehub/competitions/llm-classification-finetuning/model_2020.keras\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 146ms/step - accuracy: 0.3730 - loss: 1.0945 - val_accuracy: 0.4272 - val_loss: 1.0765 - learning_rate: 2.0000e-05\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 2e-05.\n",
            "Epoch 3/15\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.4184 - loss: 1.0757\n",
            "Epoch 3: val_loss improved from 1.07653 to 1.06742, saving model to /root/.cache/kagglehub/competitions/llm-classification-finetuning/model_2020.keras\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 147ms/step - accuracy: 0.4184 - loss: 1.0757 - val_accuracy: 0.4253 - val_loss: 1.0674 - learning_rate: 2.0000e-05\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 2e-05.\n",
            "Epoch 4/15\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.4300 - loss: 1.0670\n",
            "Epoch 4: val_loss improved from 1.06742 to 1.06409, saving model to /root/.cache/kagglehub/competitions/llm-classification-finetuning/model_2020.keras\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 146ms/step - accuracy: 0.4300 - loss: 1.0670 - val_accuracy: 0.4348 - val_loss: 1.0641 - learning_rate: 2.0000e-05\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 2e-05.\n",
            "Epoch 5/15\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.4457 - loss: 1.0617\n",
            "Epoch 5: val_loss improved from 1.06409 to 1.06106, saving model to /root/.cache/kagglehub/competitions/llm-classification-finetuning/model_2020.keras\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 144ms/step - accuracy: 0.4457 - loss: 1.0617 - val_accuracy: 0.4497 - val_loss: 1.0611 - learning_rate: 2.0000e-05\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 2e-05.\n",
            "Epoch 6/15\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.4595 - loss: 1.0540\n",
            "Epoch 6: val_loss did not improve from 1.06106\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 141ms/step - accuracy: 0.4595 - loss: 1.0540 - val_accuracy: 0.4502 - val_loss: 1.0664 - learning_rate: 2.0000e-05\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 2e-05.\n",
            "Epoch 7/15\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.4744 - loss: 1.0446\n",
            "Epoch 7: val_loss did not improve from 1.06106\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 141ms/step - accuracy: 0.4744 - loss: 1.0446 - val_accuracy: 0.4527 - val_loss: 1.0652 - learning_rate: 2.0000e-05\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 2e-05.\n",
            "Epoch 8/15\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.4842 - loss: 1.0297\n",
            "Epoch 8: val_loss did not improve from 1.06106\n",
            "\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 5.999999848427251e-06.\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 155ms/step - accuracy: 0.4842 - loss: 1.0297 - val_accuracy: 0.4524 - val_loss: 1.0759 - learning_rate: 6.0000e-06\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 2e-05.\n",
            "Epoch 9/15\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.4997 - loss: 1.0099\n",
            "Epoch 9: val_loss did not improve from 1.06106\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 141ms/step - accuracy: 0.4997 - loss: 1.0099 - val_accuracy: 0.4490 - val_loss: 1.0904 - learning_rate: 2.0000e-05\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 2e-05.\n",
            "Epoch 10/15\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.5156 - loss: 0.9923\n",
            "Epoch 10: val_loss did not improve from 1.06106\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 142ms/step - accuracy: 0.5156 - loss: 0.9923 - val_accuracy: 0.4495 - val_loss: 1.1230 - learning_rate: 2.0000e-05\n",
            "Epoch 10: early stopping\n",
            "Restoring model weights from the end of the best epoch: 5.\n",
            "Seed 2020 - Validation Loss: 1.0611 | Validation Accuracy: 44.97%\n",
            "Best epoch: 5\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 1/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/layer.py:965: UserWarning: Layer 'conv1d_16' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 0.3408 - loss: 1.0984\n",
            "Epoch 1: val_loss improved from inf to 1.09751, saving model to /root/.cache/kagglehub/competitions/llm-classification-finetuning/model_2024.keras\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 141ms/step - accuracy: 0.3408 - loss: 1.0984 - val_accuracy: 0.3491 - val_loss: 1.0975 - learning_rate: 1.0000e-05\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 2e-05.\n",
            "Epoch 2/15\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.3504 - loss: 1.0961\n",
            "Epoch 2: val_loss improved from 1.09751 to 1.08964, saving model to /root/.cache/kagglehub/competitions/llm-classification-finetuning/model_2024.keras\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 140ms/step - accuracy: 0.3504 - loss: 1.0961 - val_accuracy: 0.4173 - val_loss: 1.0896 - learning_rate: 2.0000e-05\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 2e-05.\n",
            "Epoch 3/15\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.4098 - loss: 1.0837\n",
            "Epoch 3: val_loss improved from 1.08964 to 1.07117, saving model to /root/.cache/kagglehub/competitions/llm-classification-finetuning/model_2024.keras\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 142ms/step - accuracy: 0.4098 - loss: 1.0836 - val_accuracy: 0.4230 - val_loss: 1.0712 - learning_rate: 2.0000e-05\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 2e-05.\n",
            "Epoch 4/15\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.4165 - loss: 1.0747\n",
            "Epoch 4: val_loss improved from 1.07117 to 1.06794, saving model to /root/.cache/kagglehub/competitions/llm-classification-finetuning/model_2024.keras\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 140ms/step - accuracy: 0.4165 - loss: 1.0747 - val_accuracy: 0.4239 - val_loss: 1.0679 - learning_rate: 2.0000e-05\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 2e-05.\n",
            "Epoch 5/15\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.4256 - loss: 1.0690\n",
            "Epoch 5: val_loss improved from 1.06794 to 1.06277, saving model to /root/.cache/kagglehub/competitions/llm-classification-finetuning/model_2024.keras\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 140ms/step - accuracy: 0.4256 - loss: 1.0690 - val_accuracy: 0.4459 - val_loss: 1.0628 - learning_rate: 2.0000e-05\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 2e-05.\n",
            "Epoch 6/15\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.4460 - loss: 1.0619\n",
            "Epoch 6: val_loss improved from 1.06277 to 1.06091, saving model to /root/.cache/kagglehub/competitions/llm-classification-finetuning/model_2024.keras\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 142ms/step - accuracy: 0.4460 - loss: 1.0619 - val_accuracy: 0.4544 - val_loss: 1.0609 - learning_rate: 2.0000e-05\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 2e-05.\n",
            "Epoch 7/15\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.4575 - loss: 1.0544\n",
            "Epoch 7: val_loss did not improve from 1.06091\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 141ms/step - accuracy: 0.4575 - loss: 1.0544 - val_accuracy: 0.4578 - val_loss: 1.0617 - learning_rate: 2.0000e-05\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 2e-05.\n",
            "Epoch 8/15\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.4742 - loss: 1.0446\n",
            "Epoch 8: val_loss did not improve from 1.06091\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 141ms/step - accuracy: 0.4742 - loss: 1.0446 - val_accuracy: 0.4538 - val_loss: 1.0659 - learning_rate: 2.0000e-05\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 2e-05.\n",
            "Epoch 9/15\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.4807 - loss: 1.0330\n",
            "Epoch 9: val_loss did not improve from 1.06091\n",
            "\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 5.999999848427251e-06.\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 140ms/step - accuracy: 0.4807 - loss: 1.0330 - val_accuracy: 0.4502 - val_loss: 1.0750 - learning_rate: 6.0000e-06\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 2e-05.\n",
            "Epoch 10/15\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.4968 - loss: 1.0154\n",
            "Epoch 10: val_loss did not improve from 1.06091\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 140ms/step - accuracy: 0.4968 - loss: 1.0154 - val_accuracy: 0.4482 - val_loss: 1.0895 - learning_rate: 2.0000e-05\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 2e-05.\n",
            "Epoch 11/15\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.5058 - loss: 1.0002\n",
            "Epoch 11: val_loss did not improve from 1.06091\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 142ms/step - accuracy: 0.5058 - loss: 1.0002 - val_accuracy: 0.4462 - val_loss: 1.1027 - learning_rate: 2.0000e-05\n",
            "Epoch 11: early stopping\n",
            "Restoring model weights from the end of the best epoch: 6.\n",
            "Seed 2024 - Validation Loss: 1.0609 | Validation Accuracy: 45.44%\n",
            "Best epoch: 6\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 1/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/layer.py:965: UserWarning: Layer 'conv1d_20' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.3398 - loss: 1.0985\n",
            "Epoch 1: val_loss improved from inf to 1.09780, saving model to /root/.cache/kagglehub/competitions/llm-classification-finetuning/model_2028.keras\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 142ms/step - accuracy: 0.3398 - loss: 1.0985 - val_accuracy: 0.3520 - val_loss: 1.0978 - learning_rate: 1.0000e-05\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 2e-05.\n",
            "Epoch 2/15\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 0.3594 - loss: 1.0969\n",
            "Epoch 2: val_loss improved from 1.09780 to 1.08795, saving model to /root/.cache/kagglehub/competitions/llm-classification-finetuning/model_2028.keras\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 140ms/step - accuracy: 0.3594 - loss: 1.0969 - val_accuracy: 0.4122 - val_loss: 1.0879 - learning_rate: 2.0000e-05\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 2e-05.\n",
            "Epoch 3/15\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.4132 - loss: 1.0819\n",
            "Epoch 3: val_loss improved from 1.08795 to 1.07146, saving model to /root/.cache/kagglehub/competitions/llm-classification-finetuning/model_2028.keras\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 142ms/step - accuracy: 0.4132 - loss: 1.0819 - val_accuracy: 0.4215 - val_loss: 1.0715 - learning_rate: 2.0000e-05\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 2e-05.\n",
            "Epoch 4/15\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 0.4200 - loss: 1.0729\n",
            "Epoch 4: val_loss improved from 1.07146 to 1.06561, saving model to /root/.cache/kagglehub/competitions/llm-classification-finetuning/model_2028.keras\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 140ms/step - accuracy: 0.4200 - loss: 1.0729 - val_accuracy: 0.4234 - val_loss: 1.0656 - learning_rate: 2.0000e-05\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 2e-05.\n",
            "Epoch 5/15\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.4227 - loss: 1.0679\n",
            "Epoch 5: val_loss improved from 1.06561 to 1.06520, saving model to /root/.cache/kagglehub/competitions/llm-classification-finetuning/model_2028.keras\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 140ms/step - accuracy: 0.4227 - loss: 1.0679 - val_accuracy: 0.4222 - val_loss: 1.0652 - learning_rate: 2.0000e-05\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 2e-05.\n",
            "Epoch 6/15\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.4320 - loss: 1.0628\n",
            "Epoch 6: val_loss improved from 1.06520 to 1.06042, saving model to /root/.cache/kagglehub/competitions/llm-classification-finetuning/model_2028.keras\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 142ms/step - accuracy: 0.4320 - loss: 1.0628 - val_accuracy: 0.4341 - val_loss: 1.0604 - learning_rate: 2.0000e-05\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 2e-05.\n",
            "Epoch 7/15\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.4521 - loss: 1.0547\n",
            "Epoch 7: val_loss improved from 1.06042 to 1.06041, saving model to /root/.cache/kagglehub/competitions/llm-classification-finetuning/model_2028.keras\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 140ms/step - accuracy: 0.4521 - loss: 1.0547 - val_accuracy: 0.4509 - val_loss: 1.0604 - learning_rate: 2.0000e-05\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 2e-05.\n",
            "Epoch 8/15\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.4700 - loss: 1.0443\n",
            "Epoch 8: val_loss did not improve from 1.06041\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 141ms/step - accuracy: 0.4700 - loss: 1.0443 - val_accuracy: 0.4469 - val_loss: 1.0691 - learning_rate: 2.0000e-05\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 2e-05.\n",
            "Epoch 9/15\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.4816 - loss: 1.0294\n",
            "Epoch 9: val_loss did not improve from 1.06041\n",
            "\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 5.999999848427251e-06.\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 141ms/step - accuracy: 0.4816 - loss: 1.0294 - val_accuracy: 0.4509 - val_loss: 1.0739 - learning_rate: 6.0000e-06\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 2e-05.\n",
            "Epoch 10/15\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.5000 - loss: 1.0120\n",
            "Epoch 10: val_loss did not improve from 1.06041\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 143ms/step - accuracy: 0.5000 - loss: 1.0120 - val_accuracy: 0.4473 - val_loss: 1.0924 - learning_rate: 2.0000e-05\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 2e-05.\n",
            "Epoch 11/15\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.5111 - loss: 0.9926\n",
            "Epoch 11: val_loss did not improve from 1.06041\n",
            "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 142ms/step - accuracy: 0.5112 - loss: 0.9926 - val_accuracy: 0.4436 - val_loss: 1.1199 - learning_rate: 2.0000e-05\n",
            "Epoch 11: early stopping\n",
            "Restoring model weights from the end of the best epoch: 6.\n",
            "Seed 2028 - Validation Loss: 1.0604 | Validation Accuracy: 45.09%\n",
            "Best epoch: 7\n"
          ]
        }
      ],
      "execution_count": 15
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fine Tuning the model with  \n",
        "vocab_size = 20000\n",
        "max_length = 1024\n",
        "batch_size = 32\n",
        "fine_tune_epochs = 20\n",
        "learning_rate = 5e-6  \n",
        "warmup_epochs = 2  \n",
        "weight_decay = 0.01  "
      ],
      "metadata": {
        "id": "Gz5KsvJxPfeU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Continue training from best saved model\n",
        "for seed in CFG.seeds:\n",
        "    model_name = f\"model_{seed}.keras\"\n",
        "    model_name_path = os.path.join(llm_classification_finetuning_path, model_name)\n",
        "\n",
        "    train_texts, valid_texts, train_labels, valid_labels = train_test_split(\n",
        "        prompt_list, targets, test_size=0.2, random_state=seed, stratify=targets\n",
        "    )\n",
        "    train_ds = get_dataset(train_texts, train_labels)\n",
        "    valid_ds = get_dataset(valid_texts, valid_labels, shuffle=False)\n",
        "\n",
        "    # Load existing model\n",
        "    if os.path.exists(model_name_path):\n",
        "        print(f\"Loading existing model for seed {seed}...\")\n",
        "        model = tf.keras.models.load_model(model_name_path)\n",
        "        initial_loss, initial_acc = model.evaluate(valid_ds, verbose=0)\n",
        "        print(f\"Initial - Loss: {initial_loss:.4f} | Accuracy: {initial_acc*100:.2f}%\")\n",
        "    else:\n",
        "        print(f\"No existing model found for seed {seed}, creating new one...\")\n",
        "        model = get_model()\n",
        "        initial_loss = float('inf')\n",
        "\n",
        "    # Reduce learning rate for continued training\n",
        "    current_lr = CFG.learning_rate * 0.1  # Use 10x smaller LR\n",
        "    optimizer = tf.keras.optimizers.AdamW(\n",
        "        learning_rate=current_lr,\n",
        "        weight_decay=CFG.weight_decay\n",
        "    )\n",
        "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Callbacks\n",
        "    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath=model_name_path,\n",
        "        monitor='val_loss',\n",
        "        mode='min',\n",
        "        save_best_only=True,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=5,\n",
        "        verbose=1,\n",
        "        restore_best_weights=True,\n",
        "        min_delta=1e-5\n",
        "    )\n",
        "\n",
        "    reduce_lr_callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.5,\n",
        "        patience=3,\n",
        "        min_lr=1e-8,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Continue training\n",
        "    history = model.fit(\n",
        "        train_ds,\n",
        "        epochs=CFG.fine_tune_epochs,\n",
        "        validation_data=valid_ds,\n",
        "        callbacks=[checkpoint_callback, early_stopping_callback, reduce_lr_callback],\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Load best weights and evaluate\n",
        "    model = tf.keras.models.load_model(model_name_path)\n",
        "    final_loss, final_acc = model.evaluate(valid_ds, verbose=0)\n",
        "    print(f\"Final - Loss: {final_loss:.4f} | Accuracy: {final_acc*100:.2f}%\")\n",
        "    print(f\"Improvement: {(final_loss - initial_loss):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YU3WIgaNZ5R",
        "outputId": "0fbebeda-3175-4631-942b-60f27fb837a8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading existing model for seed 42...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/layer.py:965: UserWarning: Layer 'conv1d' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial - Loss: 0.9853 | Accuracy: 53.52%\n",
            "Epoch 1/20\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.5163 - loss: 0.9988\n",
            "Epoch 1: val_loss improved from inf to 0.98159, saving model to /root/.cache/kagglehub/competitions/llm-classification-finetuning/model_42.keras\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 117ms/step - accuracy: 0.5163 - loss: 0.9988 - val_accuracy: 0.5352 - val_loss: 0.9816 - learning_rate: 5.0000e-07\n",
            "Epoch 2/20\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.5164 - loss: 0.9957\n",
            "Epoch 2: val_loss improved from 0.98159 to 0.97881, saving model to /root/.cache/kagglehub/competitions/llm-classification-finetuning/model_42.keras\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 118ms/step - accuracy: 0.5164 - loss: 0.9957 - val_accuracy: 0.5353 - val_loss: 0.9788 - learning_rate: 5.0000e-07\n",
            "Epoch 3/20\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.5203 - loss: 0.9926\n",
            "Epoch 3: val_loss improved from 0.97881 to 0.97680, saving model to /root/.cache/kagglehub/competitions/llm-classification-finetuning/model_42.keras\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 116ms/step - accuracy: 0.5203 - loss: 0.9926 - val_accuracy: 0.5365 - val_loss: 0.9768 - learning_rate: 5.0000e-07\n",
            "Epoch 4/20\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.5201 - loss: 0.9914\n",
            "Epoch 4: val_loss improved from 0.97680 to 0.97528, saving model to /root/.cache/kagglehub/competitions/llm-classification-finetuning/model_42.keras\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 116ms/step - accuracy: 0.5201 - loss: 0.9914 - val_accuracy: 0.5366 - val_loss: 0.9753 - learning_rate: 5.0000e-07\n",
            "Epoch 5/20\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.5222 - loss: 0.9908\n",
            "Epoch 5: val_loss improved from 0.97528 to 0.97404, saving model to /root/.cache/kagglehub/competitions/llm-classification-finetuning/model_42.keras\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 118ms/step - accuracy: 0.5222 - loss: 0.9908 - val_accuracy: 0.5371 - val_loss: 0.9740 - learning_rate: 5.0000e-07\n",
            "Epoch 6/20\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.5216 - loss: 0.9897\n",
            "Epoch 6: val_loss improved from 0.97404 to 0.97299, saving model to /root/.cache/kagglehub/competitions/llm-classification-finetuning/model_42.keras\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 117ms/step - accuracy: 0.5216 - loss: 0.9897 - val_accuracy: 0.5374 - val_loss: 0.9730 - learning_rate: 5.0000e-07\n",
            "Epoch 7/20\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.5197 - loss: 0.9891\n",
            "Epoch 7: val_loss improved from 0.97299 to 0.97205, saving model to /root/.cache/kagglehub/competitions/llm-classification-finetuning/model_42.keras\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 118ms/step - accuracy: 0.5197 - loss: 0.9891 - val_accuracy: 0.5370 - val_loss: 0.9721 - learning_rate: 5.0000e-07\n",
            "Epoch 8/20\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.5213 - loss: 0.9886\n",
            "Epoch 8: val_loss improved from 0.97205 to 0.97122, saving model to /root/.cache/kagglehub/competitions/llm-classification-finetuning/model_42.keras\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 118ms/step - accuracy: 0.5213 - loss: 0.9886 - val_accuracy: 0.5364 - val_loss: 0.9712 - learning_rate: 5.0000e-07\n",
            "Epoch 9/20\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.5223 - loss: 0.9877\n",
            "Epoch 9: val_loss improved from 0.97122 to 0.97046, saving model to /root/.cache/kagglehub/competitions/llm-classification-finetuning/model_42.keras\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 118ms/step - accuracy: 0.5223 - loss: 0.9876 - val_accuracy: 0.5366 - val_loss: 0.9705 - learning_rate: 5.0000e-07\n",
            "Epoch 10/20\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.5222 - loss: 0.9851\n",
            "Epoch 10: val_loss improved from 0.97046 to 0.96973, saving model to /root/.cache/kagglehub/competitions/llm-classification-finetuning/model_42.keras\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 118ms/step - accuracy: 0.5222 - loss: 0.9851 - val_accuracy: 0.5371 - val_loss: 0.9697 - learning_rate: 5.0000e-07\n",
            "Epoch 11/20\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.5205 - loss: 0.9850\n",
            "Epoch 11: val_loss improved from 0.96973 to 0.96902, saving model to /root/.cache/kagglehub/competitions/llm-classification-finetuning/model_42.keras\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 117ms/step - accuracy: 0.5205 - loss: 0.9850 - val_accuracy: 0.5373 - val_loss: 0.9690 - learning_rate: 5.0000e-07\n",
            "Epoch 12/20\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.5221 - loss: 0.9865\n",
            "Epoch 12: val_loss improved from 0.96902 to 0.96838, saving model to /root/.cache/kagglehub/competitions/llm-classification-finetuning/model_42.keras\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 118ms/step - accuracy: 0.5221 - loss: 0.9865 - val_accuracy: 0.5380 - val_loss: 0.9684 - learning_rate: 5.0000e-07\n",
            "Epoch 13/20\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.5245 - loss: 0.9856\n",
            "Epoch 13: val_loss improved from 0.96838 to 0.96777, saving model to /root/.cache/kagglehub/competitions/llm-classification-finetuning/model_42.keras\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 118ms/step - accuracy: 0.5245 - loss: 0.9856 - val_accuracy: 0.5384 - val_loss: 0.9678 - learning_rate: 5.0000e-07\n",
            "Epoch 14/20\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.5219 - loss: 0.9852\n",
            "Epoch 14: val_loss improved from 0.96777 to 0.96718, saving model to /root/.cache/kagglehub/competitions/llm-classification-finetuning/model_42.keras\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 118ms/step - accuracy: 0.5219 - loss: 0.9852 - val_accuracy: 0.5384 - val_loss: 0.9672 - learning_rate: 5.0000e-07\n",
            "Epoch 15/20\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.5225 - loss: 0.9851\n",
            "Epoch 15: val_loss improved from 0.96718 to 0.96661, saving model to /root/.cache/kagglehub/competitions/llm-classification-finetuning/model_42.keras\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 117ms/step - accuracy: 0.5225 - loss: 0.9850 - val_accuracy: 0.5386 - val_loss: 0.9666 - learning_rate: 5.0000e-07\n",
            "Epoch 16/20\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.5238 - loss: 0.9831\n",
            "Epoch 16: val_loss improved from 0.96661 to 0.96607, saving model to /root/.cache/kagglehub/competitions/llm-classification-finetuning/model_42.keras\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 117ms/step - accuracy: 0.5238 - loss: 0.9831 - val_accuracy: 0.5390 - val_loss: 0.9661 - learning_rate: 5.0000e-07\n",
            "Epoch 17/20\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.5279 - loss: 0.9812\n",
            "Epoch 17: val_loss improved from 0.96607 to 0.96555, saving model to /root/.cache/kagglehub/competitions/llm-classification-finetuning/model_42.keras\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 118ms/step - accuracy: 0.5279 - loss: 0.9812 - val_accuracy: 0.5389 - val_loss: 0.9655 - learning_rate: 5.0000e-07\n",
            "Epoch 18/20\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.5254 - loss: 0.9816\n",
            "Epoch 18: val_loss improved from 0.96555 to 0.96505, saving model to /root/.cache/kagglehub/competitions/llm-classification-finetuning/model_42.keras\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 120ms/step - accuracy: 0.5254 - loss: 0.9816 - val_accuracy: 0.5395 - val_loss: 0.9651 - learning_rate: 5.0000e-07\n",
            "Epoch 19/20\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.5263 - loss: 0.9807\n",
            "Epoch 19: val_loss improved from 0.96505 to 0.96456, saving model to /root/.cache/kagglehub/competitions/llm-classification-finetuning/model_42.keras\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 120ms/step - accuracy: 0.5263 - loss: 0.9807 - val_accuracy: 0.5398 - val_loss: 0.9646 - learning_rate: 5.0000e-07\n",
            "Epoch 20/20\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.5247 - loss: 0.9805\n",
            "Epoch 20: val_loss improved from 0.96456 to 0.96410, saving model to /root/.cache/kagglehub/competitions/llm-classification-finetuning/model_42.keras\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 121ms/step - accuracy: 0.5247 - loss: 0.9805 - val_accuracy: 0.5403 - val_loss: 0.9641 - learning_rate: 5.0000e-07\n",
            "Restoring model weights from the end of the best epoch: 20.\n",
            "Final - Loss: 0.9641 | Accuracy: 54.03%\n",
            "Improvement: -0.0212\n",
            "Loading existing model for seed 119...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/layer.py:965: UserWarning: Layer 'conv1d_8' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial - Loss: 1.0615 | Accuracy: 45.15%\n",
            "Epoch 1/20\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.4718 - loss: 1.0433\n",
            "Epoch 1: val_loss improved from inf to 1.06156, saving model to /root/.cache/kagglehub/competitions/llm-classification-finetuning/model_119.keras\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 119ms/step - accuracy: 0.4718 - loss: 1.0433 - val_accuracy: 0.4510 - val_loss: 1.0616 - learning_rate: 5.0000e-07\n",
            "Epoch 2/20\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.4728 - loss: 1.0413\n",
            "Epoch 2: val_loss did not improve from 1.06156\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 116ms/step - accuracy: 0.4728 - loss: 1.0413 - val_accuracy: 0.4509 - val_loss: 1.0617 - learning_rate: 5.0000e-07\n",
            "Epoch 3/20\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.4722 - loss: 1.0422\n",
            "Epoch 3: val_loss did not improve from 1.06156\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 115ms/step - accuracy: 0.4722 - loss: 1.0422 - val_accuracy: 0.4512 - val_loss: 1.0618 - learning_rate: 5.0000e-07\n",
            "Epoch 4/20\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.4731 - loss: 1.0409\n",
            "Epoch 4: val_loss did not improve from 1.06156\n",
            "\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 2.499999993688107e-07.\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 117ms/step - accuracy: 0.4731 - loss: 1.0409 - val_accuracy: 0.4517 - val_loss: 1.0620 - learning_rate: 5.0000e-07\n",
            "Epoch 5/20\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.4752 - loss: 1.0395\n",
            "Epoch 5: val_loss did not improve from 1.06156\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 116ms/step - accuracy: 0.4752 - loss: 1.0395 - val_accuracy: 0.4521 - val_loss: 1.0621 - learning_rate: 2.5000e-07\n",
            "Epoch 6/20\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.4744 - loss: 1.0384\n",
            "Epoch 6: val_loss did not improve from 1.06156\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 116ms/step - accuracy: 0.4744 - loss: 1.0384 - val_accuracy: 0.4522 - val_loss: 1.0622 - learning_rate: 2.5000e-07\n",
            "Epoch 6: early stopping\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "Final - Loss: 1.0616 | Accuracy: 45.10%\n",
            "Improvement: 0.0001\n",
            "Loading existing model for seed 2020...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/layer.py:965: UserWarning: Layer 'conv1d_12' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial - Loss: 1.0611 | Accuracy: 44.97%\n",
            "Epoch 1/20\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.4602 - loss: 1.0539\n",
            "Epoch 1: val_loss improved from inf to 1.06096, saving model to /root/.cache/kagglehub/competitions/llm-classification-finetuning/model_2020.keras\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 116ms/step - accuracy: 0.4602 - loss: 1.0539 - val_accuracy: 0.4501 - val_loss: 1.0610 - learning_rate: 5.0000e-07\n",
            "Epoch 2/20\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.4601 - loss: 1.0550\n",
            "Epoch 2: val_loss improved from 1.06096 to 1.06094, saving model to /root/.cache/kagglehub/competitions/llm-classification-finetuning/model_2020.keras\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 115ms/step - accuracy: 0.4601 - loss: 1.0550 - val_accuracy: 0.4497 - val_loss: 1.0609 - learning_rate: 5.0000e-07\n",
            "Epoch 3/20\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.4599 - loss: 1.0549\n",
            "Epoch 3: val_loss improved from 1.06094 to 1.06084, saving model to /root/.cache/kagglehub/competitions/llm-classification-finetuning/model_2020.keras\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 117ms/step - accuracy: 0.4599 - loss: 1.0549 - val_accuracy: 0.4500 - val_loss: 1.0608 - learning_rate: 5.0000e-07\n",
            "Epoch 4/20\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.4579 - loss: 1.0541\n",
            "Epoch 4: val_loss improved from 1.06084 to 1.06081, saving model to /root/.cache/kagglehub/competitions/llm-classification-finetuning/model_2020.keras\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 118ms/step - accuracy: 0.4579 - loss: 1.0541 - val_accuracy: 0.4503 - val_loss: 1.0608 - learning_rate: 5.0000e-07\n",
            "Epoch 5/20\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.4617 - loss: 1.0529\n",
            "Epoch 5: val_loss did not improve from 1.06081\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 117ms/step - accuracy: 0.4617 - loss: 1.0529 - val_accuracy: 0.4507 - val_loss: 1.0608 - learning_rate: 5.0000e-07\n",
            "Epoch 6/20\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.4598 - loss: 1.0528\n",
            "Epoch 6: val_loss did not improve from 1.06081\n",
            "\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 2.499999993688107e-07.\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 118ms/step - accuracy: 0.4598 - loss: 1.0528 - val_accuracy: 0.4504 - val_loss: 1.0609 - learning_rate: 5.0000e-07\n",
            "Epoch 7/20\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.4624 - loss: 1.0523\n",
            "Epoch 7: val_loss improved from 1.06081 to 1.06079, saving model to /root/.cache/kagglehub/competitions/llm-classification-finetuning/model_2020.keras\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 118ms/step - accuracy: 0.4624 - loss: 1.0523 - val_accuracy: 0.4502 - val_loss: 1.0608 - learning_rate: 2.5000e-07\n",
            "Epoch 8/20\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.4607 - loss: 1.0525\n",
            "Epoch 8: val_loss did not improve from 1.06079\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 118ms/step - accuracy: 0.4607 - loss: 1.0525 - val_accuracy: 0.4509 - val_loss: 1.0608 - learning_rate: 2.5000e-07\n",
            "Epoch 9/20\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.4602 - loss: 1.0522\n",
            "Epoch 9: val_loss did not improve from 1.06079\n",
            "\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 1.2499999968440534e-07.\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 117ms/step - accuracy: 0.4602 - loss: 1.0522 - val_accuracy: 0.4498 - val_loss: 1.0608 - learning_rate: 2.5000e-07\n",
            "Epoch 10/20\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.4629 - loss: 1.0513\n",
            "Epoch 10: val_loss did not improve from 1.06079\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 118ms/step - accuracy: 0.4629 - loss: 1.0513 - val_accuracy: 0.4502 - val_loss: 1.0608 - learning_rate: 1.2500e-07\n",
            "Epoch 11/20\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.4603 - loss: 1.0526\n",
            "Epoch 11: val_loss did not improve from 1.06079\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 119ms/step - accuracy: 0.4603 - loss: 1.0526 - val_accuracy: 0.4505 - val_loss: 1.0608 - learning_rate: 1.2500e-07\n",
            "Epoch 12/20\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.4615 - loss: 1.0521\n",
            "Epoch 12: val_loss did not improve from 1.06079\n",
            "\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 6.249999984220267e-08.\n",
            "\u001b[1m1437/1437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 119ms/step - accuracy: 0.4615 - loss: 1.0521 - val_accuracy: 0.4503 - val_loss: 1.0608 - learning_rate: 1.2500e-07\n",
            "Epoch 12: early stopping\n",
            "Restoring model weights from the end of the best epoch: 7.\n",
            "Final - Loss: 1.0608 | Accuracy: 45.02%\n",
            "Improvement: -0.0003\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv(os.path.join(llm_classification_finetuning_path, 'test.csv'))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-08T12:24:08.686406Z",
          "iopub.execute_input": "2024-12-08T12:24:08.68727Z",
          "iopub.status.idle": "2024-12-08T12:24:08.698325Z",
          "shell.execute_reply.started": "2024-12-08T12:24:08.687225Z",
          "shell.execute_reply": "2024-12-08T12:24:08.697233Z"
        },
        "id": "sRjn2GI4uGgt"
      },
      "outputs": [],
      "execution_count": 14
    },
    {
      "cell_type": "code",
      "source": [
        "test_prompt_list = []\n",
        "for i in tqdm(range(len(test_df))):\n",
        "    prompts = json.loads(test_df.iloc[i][\"prompt\"])\n",
        "    response_a = json.loads(test_df.iloc[i][\"response_a\"])\n",
        "    response_b = json.loads(test_df.iloc[i][\"response_b\"])\n",
        "    conversation_a = \"\"\n",
        "    conversation_b = \"\"\n",
        "    for j in range(len(prompts)):\n",
        "        if response_a[j] is None:\n",
        "            response_a[j] = \"None\"\n",
        "        if response_b[j] is None:\n",
        "            response_b[j] = \"None\"\n",
        "        conversation_a += prompts[j] + \"\\n\"\n",
        "        conversation_a += response_a[j] + \"\\n\"\n",
        "        conversation_b += prompts[j] + \"\\n\"\n",
        "        conversation_b += response_b[j] + \"\\n\"\n",
        "    test_prompt_list.append((conversation_a, conversation_b))\n",
        "len(test_prompt_list)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-08T12:24:08.701954Z",
          "iopub.execute_input": "2024-12-08T12:24:08.702599Z",
          "iopub.status.idle": "2024-12-08T12:24:08.72494Z",
          "shell.execute_reply.started": "2024-12-08T12:24:08.70257Z",
          "shell.execute_reply": "2024-12-08T12:24:08.724069Z"
        },
        "id": "2WNZTcFsuGgu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "85287f32eae746709a21593f9c8cbeb4",
            "5a7db1c1997c4df1a551b96aa8c330be",
            "3e3d156a5bba469399b8735efa3f21f5",
            "f1956da38454405fa07438b3929673a8",
            "577eeeee847c483fa8a3e7e91de58d5e",
            "064951b4aec0427ea19566197500db20",
            "640e813043c44be0bd6db7b7821e78ff",
            "e7adf8de1cae473c8045758031538e2b",
            "536dcd96ccdb42f18fbdedd929c3ecb6",
            "04390f57514b424a9854c1498582469a",
            "0a5c4ce2762044e4b3b4fb8b7de52803"
          ]
        },
        "outputId": "d5d0ac39-b4bc-4767-b33e-04e995155779"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "85287f32eae746709a21593f9c8cbeb4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "execution_count": 15
    },
    {
      "cell_type": "code",
      "source": [
        "def get_test_dataset(prompt_list, batch_size=128):\n",
        "    part1 = [item[0] for item in prompt_list]\n",
        "    part2 = [item[1] for item in prompt_list]\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(((part1, part2), [0] * len(prompt_list)))\n",
        "    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "    return dataset"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-08T12:24:08.725955Z",
          "iopub.execute_input": "2024-12-08T12:24:08.726271Z",
          "iopub.status.idle": "2024-12-08T12:24:08.743401Z",
          "shell.execute_reply.started": "2024-12-08T12:24:08.726244Z",
          "shell.execute_reply": "2024-12-08T12:24:08.742543Z"
        },
        "id": "0c2-xIGWuGgu"
      },
      "outputs": [],
      "execution_count": 16
    },
    {
      "cell_type": "code",
      "source": [
        "test_ds = get_test_dataset(test_prompt_list)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-08T12:24:08.744365Z",
          "iopub.execute_input": "2024-12-08T12:24:08.744637Z",
          "iopub.status.idle": "2024-12-08T12:24:08.760822Z",
          "shell.execute_reply.started": "2024-12-08T12:24:08.744612Z",
          "shell.execute_reply": "2024-12-08T12:24:08.760004Z"
        },
        "id": "zFqj21HzuGgu"
      },
      "outputs": [],
      "execution_count": 17
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "V84N0Bk7uGgv"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}